# Workshop // Exploring Gender Bias in Word Embeddings
> Credit: [Shlomi Hod](https://github.com/shlomihod) & [Responsibly](https://github.com/ResponsiblyAI/responsibly)

> Towards an intuitive technical understanding of bias in machine learning systems

<br />

<small>
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" width="80" height="15" src="https://i.creativecommons.org/l/by/4.0/80x15.png" /></a> This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
</small>

<img style="display: block" height="150px" src="https://upload.wikimedia.org/wikipedia/commons/5/52/Global_Open_Educational_Resources_Logo_-_White_background_variation.svg" />

## Check the website for complete information:
## https://learn.responsibly.ai/word-embedding

### In a Nutshell

- In this **90 minutes** workshop, we will explore bias
  in word embeddings - a **widespread building block** of many machine learning models
  that work with human languages.
- Word embeddings have an easy-to-explain representation
  that allows an **intuitive understanding** of this building block
  and its **potential biases**.
- Through the exploration, we will raise practical, methodological
  and philosophical questions about the **ethics of AI**.
- The workshop is designed to be **adaptive** to a **diverse audience**:
  from without any background in machine learning or programming
  to data science practitioners - **no technical background is required!**
- The workshop is **hands-on** and **interactive**,
  and will use the same tools that data scientists are using.
